{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "from shutil import copyfile\n",
    "import pydicom as dicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters here\n",
    "savepath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\data'\n",
    "seed = 0\n",
    "np.random.seed(seed) # Reset the seed so all runs are the same.\n",
    "random.seed(seed)\n",
    "MAXVAL = 255  # Range [0 255]\n",
    "\n",
    "# path to covid-19 dataset from https://github.com/ieee8023/covid-chestxray-dataset\n",
    "cohen_imgpath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\covid-chestxray-dataset-master\\images' \n",
    "cohen_csvpath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\covid-chestxray-dataset-master\\metadata.csv'\n",
    "\n",
    "# path to covid-14 dataset from https://github.com/agchung/Figure1-COVID-chestxray-dataset\n",
    "fig1_imgpath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\Figure1-COVID-chestxray-dataset-master\\images'\n",
    "fig1_csvpath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\Figure1-COVID-chestxray-dataset-master\\metadata.csv'\n",
    "\n",
    "# path to https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n",
    "rsna_datapath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\rsna-pneumonia-detection-challenge\\rsna-pneumonia-detection-challenge'\n",
    "# get all the normal from here\n",
    "rsna_csvname = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\rsna-pneumonia-detection-challenge\\stage_2_detailed_class_info.csv' \n",
    "# get all the 1s from here since 1 indicate pneumonia\n",
    "# found that images that aren't pneunmonia and also not normal are classified as 0s\n",
    "rsna_csvname2 = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\rsna-pneumonia-detection-challenge\\stage_2_train_labels.csv' \n",
    "rsna_imgpath = r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\rsna-pneumonia-detection-challenge\\stage_2_train_images'\n",
    "\n",
    "# parameters for COVIDx dataset\n",
    "train = []\n",
    "test = []\n",
    "test_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "train_count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "\n",
    "mapping = dict()\n",
    "mapping['COVID-19'] = 'COVID-19'\n",
    "mapping['SARS'] = 'pneumonia'\n",
    "mapping['MERS'] = 'pneumonia'\n",
    "mapping['Streptococcus'] = 'pneumonia'\n",
    "mapping['Klebsiella'] = 'pneumonia'\n",
    "mapping['Chlamydophila'] = 'pneumonia'\n",
    "mapping['Legionella'] = 'pneumonia'\n",
    "mapping['Normal'] = 'normal'\n",
    "mapping['Lung Opacity'] = 'pneumonia'\n",
    "mapping['1'] = 'pneumonia'\n",
    "\n",
    "# train/test split\n",
    "split = 0.1\n",
    "\n",
    "# to avoid duplicates\n",
    "patient_imgpath = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/mlmed/torchxrayvision/blob/master/torchxrayvision/datasets.py#L814\n",
    "cohen_csv = pd.read_csv(cohen_csvpath, nrows=None)\n",
    "#idx_pa = csv[\"view\"] == \"PA\"  # Keep only the PA view\n",
    "views = [\"PA\", \"AP\", \"AP Supine\", \"AP semi erect\", \"AP erect\"]\n",
    "cohen_idx_keep = cohen_csv.view.isin(views)\n",
    "cohen_csv = cohen_csv[cohen_idx_keep]\n",
    "\n",
    "fig1_csv = pd.read_csv(fig1_csvpath, encoding='ISO-8859-1', nrows=None)\n",
    "#fig1_idx_keep = fig1_csv.view.isin(views)\n",
    "#fig1_csv = fig1_csv[fig1_idx_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution from covid-chestxray-dataset:\n",
      "{'normal': 0, 'pneumonia': 33, 'COVID-19': 254}\n"
     ]
    }
   ],
   "source": [
    "# get non-COVID19 viral, bacteria, and COVID-19 infections from covid-chestxray-dataset\n",
    "# stored as patient id, image filename and label\n",
    "filename_label = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
    "count = {'normal': 0, 'pneumonia': 0, 'COVID-19': 0}\n",
    "for index, row in cohen_csv.iterrows():\n",
    "    f = row['finding'].split(',')[0] # take the first finding, for the case of COVID-19, ARDS\n",
    "    if f in mapping: # \n",
    "        count[mapping[f]] += 1\n",
    "        entry = [str(row['patientid']), row['filename'], mapping[f], row['view']]\n",
    "        filename_label[mapping[f]].append(entry)\n",
    "        \n",
    "for index, row in fig1_csv.iterrows():\n",
    "    if not str(row['finding']) == 'nan':\n",
    "        f = row['finding'].split(',')[0] # take the first finding\n",
    "        if f in mapping: # \n",
    "            count[mapping[f]] += 1\n",
    "            if os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.jpg')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.jpg', mapping[f]]\n",
    "            elif os.path.exists(os.path.join(fig1_imgpath, row['patientid'] + '.png')):\n",
    "                entry = [row['patientid'], row['patientid'] + '.png', mapping[f]]\n",
    "            filename_label[mapping[f]].append(entry)\n",
    "\n",
    "print('Data distribution from covid-chestxray-dataset:')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  pneumonia\n",
      "Test patients:  ['8', '31']\n",
      "Key:  COVID-19\n",
      "Test patients:  ['19', '20', '36', '42', '86', '94', '97', '117', '132', '138', '144', '150', '163', '169']\n",
      "test count:  {'normal': 0, 'pneumonia': 5, 'COVID-19': 31}\n",
      "train count:  {'normal': 0, 'pneumonia': 28, 'COVID-19': 223}\n"
     ]
    }
   ],
   "source": [
    "# add covid-chestxray-dataset into COVIDx dataset\n",
    "# since covid-chestxray-dataset doesn't have test dataset\n",
    "# split into train/test by patientid\n",
    "# for COVIDx:\n",
    "# patient 8 is used as non-COVID19 viral test\n",
    "# patient 31 is used as bacterial test\n",
    "# patients 19, 20, 36, 42, 86 are used as COVID-19 viral test\n",
    "\n",
    "for key in filename_label.keys():\n",
    "    arr = np.array(filename_label[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    # split by patients\n",
    "    # num_diff_patients = len(np.unique(arr[:,0]))\n",
    "    # num_test = max(1, round(split*num_diff_patients))\n",
    "    # select num_test number of random patients\n",
    "    if key == 'pneumonia':\n",
    "        test_patients = ['8', '31']\n",
    "    elif key == 'COVID-19':\n",
    "        test_patients = ['19', '20', '36', '42', '86', \n",
    "                         '94', '97', '117', '132', \n",
    "                         '138', '144', '150', '163', '169'] # random.sample(list(arr[:,0]), num_test)\n",
    "    else: \n",
    "        test_patients = []\n",
    "    print('Key: ', key)\n",
    "    print('Test patients: ', test_patients)\n",
    "    # go through all the patients\n",
    "    for patient in arr:\n",
    "        if patient[0] not in patient_imgpath:\n",
    "            patient_imgpath[patient[0]] = [patient[1]]\n",
    "        else:\n",
    "            if patient[1] not in patient_imgpath[patient[0]]:\n",
    "                patient_imgpath[patient[0]].append(patient[1])\n",
    "            else:\n",
    "                continue  # skip since image has already been written\n",
    "        if patient[0] in test_patients:\n",
    "            copyfile(os.path.join(cohen_imgpath, patient[1]), os.path.join(savepath, 'test', patient[1]))\n",
    "            test.append(patient)\n",
    "            test_count[patient[2]] += 1\n",
    "        else:\n",
    "            if 'COVID' in patient[0]:\n",
    "                copyfile(os.path.join(fig1_imgpath, patient[1]), os.path.join(savepath, 'train', patient[1]))\n",
    "            else:\n",
    "                copyfile(os.path.join(cohen_imgpath, patient[1]), os.path.join(savepath, 'train', patient[1]))\n",
    "            train.append(patient)\n",
    "            train_count[patient[2]] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test count:  {'normal': 885, 'pneumonia': 594, 'COVID-19': 31}\n",
      "train count:  {'normal': 7966, 'pneumonia': 5451, 'COVID-19': 223}\n"
     ]
    }
   ],
   "source": [
    "# add normal and rest of pneumonia cases from https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\n",
    "csv_normal = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname), nrows=None)\n",
    "csv_pneu = pd.read_csv(os.path.join(rsna_datapath, rsna_csvname2), nrows=None)\n",
    "patients = {'normal': [], 'pneumonia': []}\n",
    "\n",
    "for index, row in csv_normal.iterrows():\n",
    "    if row['class'] == 'Normal':\n",
    "        patients['normal'].append(row['patientId'])\n",
    "\n",
    "for index, row in csv_pneu.iterrows():\n",
    "    if int(row['Target']) == 1:\n",
    "        patients['pneumonia'].append(row['patientId'])\n",
    "\n",
    "for key in patients.keys():\n",
    "    arr = np.array(patients[key])\n",
    "    if arr.size == 0:\n",
    "        continue\n",
    "    # split by patients \n",
    "    # num_diff_patients = len(np.unique(arr))\n",
    "    # num_test = max(1, round(split*num_diff_patients))\n",
    "    test_patients = np.load(r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\rsna_test_patients_{}.npy'.format(key)) # random.sample(list(arr), num_test), download the .npy files from the repo.\n",
    "    # np.save('rsna_test_patients_{}.npy'.format(key), np.array(test_patients))\n",
    "    for patient in arr:\n",
    "        if patient not in patient_imgpath:\n",
    "            patient_imgpath[patient] = [patient]\n",
    "        else:\n",
    "            continue  # skip since image has already been written\n",
    "                \n",
    "        ds = dicom.dcmread(os.path.join(rsna_datapath, rsna_imgpath, patient + '.dcm'))\n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        imgname = patient + '.png'\n",
    "        if patient in test_patients:\n",
    "            cv2.imwrite(os.path.join(savepath, 'test', imgname), pixel_array_numpy)\n",
    "            test.append([patient, imgname, key])\n",
    "            test_count[key] += 1\n",
    "        else:\n",
    "            cv2.imwrite(os.path.join(savepath, 'train', imgname), pixel_array_numpy)\n",
    "            train.append([patient, imgname, key])\n",
    "            train_count[key] += 1\n",
    "\n",
    "print('test count: ', test_count)\n",
    "print('train count: ', train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final stats\n",
      "Train count:  {'normal': 7966, 'pneumonia': 5451, 'COVID-19': 223}\n",
      "Test count:  {'normal': 885, 'pneumonia': 594, 'COVID-19': 31}\n",
      "Total length of train:  13640\n",
      "Total length of test:  1510\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final stats\n",
    "print('Final stats')\n",
    "print('Train count: ', train_count)\n",
    "print('Test count: ', test_count)\n",
    "print('Total length of train: ', len(train))\n",
    "print('Total length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# export to train and test csv\n",
    "# format as patientid, filename, label, separated by a space\n",
    "train_file = open(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\train_split_v3.txt\",\"a\") \n",
    "for sample in train:\n",
    "    if len(sample) == 4:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + ' ' + sample[3] + '\\n'\n",
    "    else:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + '\\n'\n",
    "    train_file.write(info)\n",
    "\n",
    "train_file.close()\n",
    "\n",
    "test_file = open(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\test_split_v3.txt\", \"a\")\n",
    "for sample in test:\n",
    "    if len(sample) == 4:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + ' ' + sample[3] + '\\n'\n",
    "    else:\n",
    "        info = str(sample[0]) + ' ' + sample[1] + ' ' + sample[2] + '\\n'\n",
    "    test_file.write(info)\n",
    "\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def _process_csv_file(file):\n",
    "    with open(file, 'r') as fr:\n",
    "        files = fr.readlines()\n",
    "    return files\n",
    "\n",
    "class BalanceCovidDataset(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_dir,\n",
    "            csv_file,\n",
    "            is_training=True,\n",
    "            batch_size=8,\n",
    "            input_shape=(224, 224),\n",
    "            n_classes=3,\n",
    "            num_channels=3,\n",
    "            mapping={\n",
    "                'normal': 0,\n",
    "                'pneumonia': 1,\n",
    "                'COVID-19': 2\n",
    "            },\n",
    "            shuffle=True,\n",
    "            augmentation=True,\n",
    "            covid_percent=0.3,\n",
    "            class_weights=[1., 1., 6.]\n",
    "    ):\n",
    "        'Initialization'\n",
    "        self.datadir = data_dir\n",
    "        self.dataset = _process_csv_file(csv_file)\n",
    "        self.is_training = is_training\n",
    "        self.batch_size = batch_size\n",
    "        self.N = len(self.dataset)\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.num_channels = num_channels\n",
    "        self.mapping = mapping\n",
    "        self.shuffle = True\n",
    "        self.covid_percent = covid_percent\n",
    "        self.class_weights = class_weights\n",
    "        self.n = 0\n",
    "\n",
    "        if augmentation:\n",
    "            self.augmentation = ImageDataGenerator(\n",
    "                featurewise_center=False,\n",
    "                featurewise_std_normalization=False,\n",
    "                rotation_range=10,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                brightness_range=(0.9, 1.1),\n",
    "                zoom_range=(0.85, 1.15),\n",
    "                fill_mode='constant',\n",
    "                cval=0.,\n",
    "            )\n",
    "\n",
    "        datasets = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
    "        for l in self.dataset:\n",
    "            datasets[l.split()[-1]].append(l)\n",
    "        self.datasets = [\n",
    "            datasets['normal'] + datasets['pneumonia'],\n",
    "            datasets['COVID-19'],\n",
    "        ]\n",
    "        print(len(self.datasets[0]), len(self.datasets[1]))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __next__(self):\n",
    "        # Get one batch of data\n",
    "        batch_x, batch_y, weights = self.__getitem__(self.n)\n",
    "        # Batch index\n",
    "        self.n += 1\n",
    "\n",
    "        # If we have processed the entire dataset then\n",
    "        if self.n >= self.__len__():\n",
    "            self.on_epoch_end\n",
    "            self.n = 0\n",
    "\n",
    "        return batch_x, batch_y, weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.datasets[0]) / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            for v in self.datasets:\n",
    "                np.random.shuffle(v)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x, batch_y = np.zeros(\n",
    "            (self.batch_size, *self.input_shape,\n",
    "             self.num_channels)), np.zeros(self.batch_size)\n",
    "\n",
    "        batch_files = self.datasets[0][idx * self.batch_size:(idx + 1) *\n",
    "                                       self.batch_size]\n",
    "\n",
    "        # upsample covid cases\n",
    "        covid_size = max(int(len(batch_files) * self.covid_percent), 1)\n",
    "        covid_inds = np.random.choice(np.arange(len(batch_files)),\n",
    "                                      size=covid_size,\n",
    "                                      replace=False)\n",
    "        covid_files = np.random.choice(self.datasets[1],\n",
    "                                       size=covid_size,\n",
    "                                       replace=False)\n",
    "        for i in range(covid_size):\n",
    "            batch_files[covid_inds[i]] = covid_files[i]\n",
    "\n",
    "        for i in range(len(batch_files)):\n",
    "            sample = batch_files[i].split()\n",
    "\n",
    "            if self.is_training:\n",
    "                folder = 'train'\n",
    "            else:\n",
    "                folder = 'test'\n",
    "\n",
    "            x = cv2.imread(os.path.join(self.datadir, folder, sample[1]))\n",
    "            h, w, c = x.shape\n",
    "            x = x[int(h/6):, :]\n",
    "            x = cv2.resize(x, self.input_shape)\n",
    "\n",
    "            if self.is_training and hasattr(self, 'augmentation'):\n",
    "                x = self.augmentation.random_transform(x)\n",
    "\n",
    "            x = x.astype('float32') / 255.0\n",
    "            y = self.mapping[sample[2]]\n",
    "\n",
    "            batch_x[i] = x\n",
    "            batch_y[i] = y\n",
    "\n",
    "        class_weights = self.class_weights\n",
    "        weights = np.take(class_weights, batch_y.astype('int64'))\n",
    "\n",
    "        return batch_x, keras.utils.to_categorical(batch_y, num_classes=self.n_classes), weights\n",
    "\n",
    "class BalanceDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 is_training=True,\n",
    "                 batch_size=8,\n",
    "                 input_shape=(224,224),\n",
    "                 n_classes=3,\n",
    "                 num_channels=3,\n",
    "                 mapping={'normal': 0, 'pneumonia': 1, 'COVID-19': 2},\n",
    "                 shuffle=True,\n",
    "                 augmentation=True,\n",
    "                 datadir='data',\n",
    "                 class_weights=[1., 1., 25.]\n",
    "                 ):\n",
    "        'Initialization'\n",
    "        self.datadir = datadir\n",
    "        self.dataset = dataset\n",
    "        self.is_training = is_training\n",
    "        self.batch_size = batch_size\n",
    "        self.N = len(self.dataset)\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.num_channels = num_channels\n",
    "        self.mapping = mapping\n",
    "        self.shuffle = True\n",
    "        self.n = 0\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "        if augmentation:\n",
    "            self.augmentation = ImageDataGenerator(\n",
    "                featurewise_center=False,\n",
    "                featurewise_std_normalization=False,\n",
    "                rotation_range=10,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                brightness_range=(0.9, 1.1),\n",
    "                fill_mode='constant',\n",
    "                cval=0.,\n",
    "            )\n",
    "\n",
    "        datasets = {'normal': [], 'pneumonia': [], 'COVID-19': []}\n",
    "        for l in dataset:\n",
    "            datasets[l.split()[-1]].append(l)\n",
    "        self.datasets = [\n",
    "            datasets['normal'] + datasets['pneumonia'],\n",
    "            datasets['COVID-19'],\n",
    "        ]\n",
    "        print(len(self.datasets[0]), len(self.datasets[1]))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __next__(self):\n",
    "        # Get one batch of data\n",
    "        batch_x, batch_y, weights = self.__getitem__(self.n)\n",
    "        # Batch index\n",
    "        self.n += 1\n",
    "\n",
    "        # If we have processed the entire dataset then\n",
    "        if self.n >= self.__len__():\n",
    "            self.on_epoch_end\n",
    "            self.n = 0\n",
    "\n",
    "        return batch_x, batch_y, weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.datasets[0]) / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            for v in self.datasets:\n",
    "                np.random.shuffle(v)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x, batch_y = np.zeros((self.batch_size, *self.input_shape, self.num_channels)), np.zeros(self.batch_size)\n",
    "\n",
    "        batch_files = self.datasets[0][idx*self.batch_size : (idx+1)*self.batch_size]\n",
    "        batch_files[np.random.randint(self.batch_size)] = np.random.choice(self.datasets[1])\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            sample = batch_files[i].split()\n",
    "\n",
    "            if self.is_training:\n",
    "                folder = 'train'\n",
    "            else:\n",
    "                folder = 'test'\n",
    "\n",
    "            x = cv2.imread(os.path.join(self.datadir, folder, sample[1]))\n",
    "            h, w, c = x.shape\n",
    "            x = x[int(h/6):, :]\n",
    "            x = cv2.resize(x, self.input_shape)\n",
    "\n",
    "            if self.is_training and hasattr(self, 'augmentation'):\n",
    "                x = self.augmentation.random_transform(x)\n",
    "\n",
    "            x = x.astype('float32') / 255.0\n",
    "            y = self.mapping[sample[2]]\n",
    "\n",
    "            batch_x[i] = x\n",
    "            batch_y[i] = y\n",
    "\n",
    "        weights = np.take(self.class_weights, batch_y.astype('int64'))\n",
    "\n",
    "        return batch_x, keras.utils.to_categorical(batch_y, num_classes=self.n_classes), weights\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 is_training=True,\n",
    "                 batch_size=8,\n",
    "                 input_shape=(224,224),\n",
    "                 n_classes=3,\n",
    "                 num_channels=3,\n",
    "                 mapping={'normal': 0, 'pneumonia': 1, 'COVID-19': 2},\n",
    "                 shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "        self.is_training = is_training\n",
    "        self.batch_size = batch_size\n",
    "        self.N = len(self.dataset)\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.num_channels = num_channels\n",
    "        self.mapping = mapping\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.N / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.dataset = shuffle(self.dataset, random_state=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x, batch_y = np.zeros((self.batch_size, *self.input_shape, self.num_channels)), np.zeros(self.batch_size)\n",
    "        for i in range(self.batch_size):\n",
    "            index = min((idx * self.batch_size) + i, self.N-1)\n",
    "\n",
    "            sample = self.dataset[index].split()\n",
    "\n",
    "            if self.is_training:\n",
    "                folder = 'train'\n",
    "            else:\n",
    "                folder = 'test'\n",
    "\n",
    "            x = cv2.imread(os.path.join('data', folder, sample[1]))\n",
    "            x = cv2.resize(x, self.input_shape)\n",
    "            x = x.astype('float32') / 255.0\n",
    "            #y = int(sample[1])\n",
    "            y = self.mapping[sample[2]]\n",
    "\n",
    "            batch_x[i] = x\n",
    "            batch_y[i] = y\n",
    "\n",
    "        return batch_x, keras.utils.to_categorical(batch_y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, argparse\n",
    "import cv2\n",
    "\n",
    "mapping = {'normal': 0, 'pneumonia': 1, 'COVID-19': 2}\n",
    "\n",
    "def eval(sess, graph, testfile, testfolder):\n",
    "    image_tensor = graph.get_tensor_by_name(\"input_1:0\")\n",
    "    pred_tensor = graph.get_tensor_by_name(\"dense_3/Softmax:0\")\n",
    "\n",
    "    y_test = []\n",
    "    pred = []\n",
    "    for i in range(len(testfile)):\n",
    "        line = testfile[i].split()\n",
    "        x = cv2.imread(os.path.join('data', testfolder, line[1]))\n",
    "        h, w, c = x.shape\n",
    "        x = x[int(h/6):, :]\n",
    "        x = cv2.resize(x, (224, 224))\n",
    "        x = x.astype('float32') / 255.0\n",
    "        y_test.append(mapping[line[2]])\n",
    "        pred.append(np.array(sess.run(pred_tensor, feed_dict={image_tensor: np.expand_dims(x, axis=0)})).argmax(axis=1))\n",
    "    y_test = np.array(y_test)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    matrix = confusion_matrix(y_test, pred)\n",
    "    matrix = matrix.astype('float')\n",
    "    #cm_norm = matrix / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    print(matrix)\n",
    "    #class_acc = np.array(cm_norm.diagonal())\n",
    "    class_acc = [matrix[i,i]/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\n",
    "    print('Sens Normal: {0:.3f}, Pneumonia: {1:.3f}, COVID-19: {2:.3f}'.format(class_acc[0],\n",
    "                                                                               class_acc[1],\n",
    "                                                                               class_acc[2]))\n",
    "    ppvs = [matrix[i,i]/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\n",
    "    print('PPV Normal: {0:.3f}, Pneumonia {1:.3f}, COVID-19: {2:.3f}'.format(ppvs[0],\n",
    "                                                                             ppvs[1],\n",
    "                                                                             ppvs[2]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    weightspath=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master'\n",
    "    metaname='model.meta'\n",
    "    ckptname='model'\n",
    "    testfile=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\test_COVIDx.txt'\n",
    "    testfolder=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\data\\test'\n",
    "\n",
    "    \n",
    "\n",
    "    '''sess = tf.Session()\n",
    "    tf.get_default_graph()\n",
    "    saver = tf.train.import_meta_graph(os.path.join(weightspath, metaname))\n",
    "    saver.restore(sess, os.path.join(weightspath, ackptname))\n",
    "\n",
    "    graph = tf.get_default_graph()'''\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13417 152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='COVID-Net Training Script')\n",
    "epochs=10\n",
    "lr=0.00002\n",
    "bs=8\n",
    "weightspath=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\models\\COVIDNet-CXR-Large'\n",
    "metaname='model.meta'\n",
    "ckptname='model-8485'\n",
    "trainfile=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\train_COVIDx2.txt'\n",
    "testfile=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\test_COVIDx2.txt'\n",
    "name=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\COVIDNet'\n",
    "datadir=r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\data'\n",
    "covid_weight=12.\n",
    "covid_percent=0.3\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate =lr\n",
    "batch_size = bs\n",
    "display_step = 1\n",
    "\n",
    "'''# output path\n",
    "outputPath = './output/'\n",
    "runID = name + '-lr' + str(learning_rate)\n",
    "runPath = outputPath + runID\n",
    "pathlib.Path(runPath).mkdir(parents=True, exist_ok=True)\n",
    "print('Output: ' + runPath)'''\n",
    "\n",
    "with open(trainfile) as f:\n",
    "    trainfiles = f.readlines()\n",
    "with open(testfile) as f:\n",
    "    testfiles = f.readlines()\n",
    "\n",
    "generator = BalanceCovidDataset(data_dir=datadir,\n",
    "                                csv_file=trainfile,\n",
    "                                covid_percent=covid_percent,\n",
    "                                class_weights=[1., 1.,covid_weight])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,weights=next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "for i in range(1677):\n",
    "        batch_x, batch_y, weights = next(generator)\n",
    "        x_train=np.vstack((x_train,batch_x))\n",
    "        y_train=np.vstack((y_train,batch_y))\n",
    "        weights=[]\n",
    "        if(i%500==0):\n",
    "            print(i)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    }
   ],
   "source": [
    "p=0\n",
    "for i in range(1,1677):\n",
    "        batch_x, batch_y, weights = next(generator)\n",
    "        x_train=np.vstack((x_train,batch_x))\n",
    "        y_train=np.vstack((y_train,batch_y))\n",
    "        weights=[]\n",
    "        if(i%1676==0) :\n",
    "            print(i)\n",
    "            np.save(r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\numpy\\x_train{}'.format(10),x_train)\n",
    "            np.save(r'C:\\Users\\siris\\OneDrive\\Desktop\\215\\Final_Project\\data\\COVID-Net-master\\numpy\\y_train{}'.format(10),y_train)\n",
    "            \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
